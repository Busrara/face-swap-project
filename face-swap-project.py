# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from insightface.app import FaceAnalysis
from insightface.model_zoo import get_model
from huggingface_hub import hf_hub_download
import albumentations as A
import pickle
from sklearn.cluster import KMeans

class EnhancedFaceSwapper:
    def __init__(self, ctx_id=0, det_size=(640, 640)):
        # Initialize face analysis (detection + landmarks + embedding)
        self.app = FaceAnalysis(name='buffalo_l')
        self.app.prepare(ctx_id=ctx_id, det_size=det_size)

        model_path = hf_hub_download(
            repo_id="Aitrepreneur/insightface",
            filename="inswapper_128.onnx"
        )
        self.swapper = get_model(model_path, download=False)

        # Setup augmentations
        self.augmentation = A.Compose([
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5),
            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
            A.MotionBlur(blur_limit=3, p=0.2),
            A.RandomGamma(gamma_limit=(80, 120), p=0.3),
            A.CLAHE(clip_limit=2.0, p=0.3),
            A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.3),
            A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, p=0.2),
        ])

        self.quality_threshold = 0.3

    def augment_image(self, image):
        augmented = self.augmentation(image=image)
        return augmented['image']

    def assess_face_quality(self, face):
        bbox = face['bbox']
        face_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
        confidence = face.get('det_score', 0)
        quality_score = min(1.0, confidence * (face_area / 10000))
        return quality_score

    def create_face_dataset(self, images, output_dir="face_dataset"):
        os.makedirs(output_dir, exist_ok=True)
        face_data = []
        for i, img in enumerate(images):
            print(f"Processing image {i+1}/{len(images)}")
            if isinstance(img, str):
                img = cv2.imread(img)
            if img is None:
                print("Image load failed:", img)
                continue
            faces = self.app.get(img)
            for j, face in enumerate(faces):
                quality = self.assess_face_quality(face)
                if quality < self.quality_threshold:
                    continue
                bbox = [int(x) for x in face['bbox']]
                face_region = img[bbox[1]:bbox[3], bbox[0]:bbox[2]]
                # Save original face
                path = os.path.join(output_dir, f"face_{i}_{j}_original.jpg")
                cv2.imwrite(path, face_region)
                face_data.append({'image': img, 'face': face, 'quality': quality, 'face_region': face_region})
        print(f"Created dataset with {len(face_data)} faces")
        return face_data

    def cluster_faces(self, face_data, n_clusters=5):
        embeddings = []
        for data in face_data:
            # embedding extraction
            emb = data['face'].get('embedding')
            if emb is None:
                emb = np.zeros(512)
            embeddings.append(emb)
        embeddings = np.array(embeddings)
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(embeddings)
        for i, cluster in enumerate(clusters):
            face_data[i]['cluster'] = cluster
        return face_data, clusters

    def smart_face_swap(self, source_img, target_img, quality_filter=True):
        source_faces = self.app.get(source_img)
        target_faces = self.app.get(target_img)
        if not source_faces or not target_faces:
            print("Face not detected on source or target")
            return target_img
        if quality_filter:
            source_qualities = [self.assess_face_quality(f) for f in source_faces]
            target_qualities = [self.assess_face_quality(f) for f in target_faces]
            best_source = source_faces[np.argmax(source_qualities)]
            best_targets = [f for i, f in enumerate(target_faces) if target_qualities[i] > self.quality_threshold]
        else:
            best_source = source_faces[0]
            best_targets = target_faces
        result = target_img.copy()
        for tgt_face in best_targets:
            # swap faces by inswapper model
            result = self.swapper.get(result, tgt_face, best_source, paste_back=True)
        return result

    def visualize_results(self, original, swapped, title="Face Swap Result"):
        plt.figure(figsize=(10,5))
        plt.subplot(1,2,1)
        plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))
        plt.title("Original")
        plt.axis('off')
        plt.subplot(1,2,2)
        plt.imshow(cv2.cvtColor(swapped, cv2.COLOR_BGR2RGB))
        plt.title(title)
        plt.axis('off')
        plt.show()

def main():
    swapper = EnhancedFaceSwapper()

    # Load your images here (replace with your local paths or images)
    source_img_path = '/content/portrait-blonde-woman-looking-photographer.jpg'
    target_img_path = '/content/smiling-young-beautiful-girl-pointing-right-side-with-copy-space.jpg'

    source_img = cv2.imread(source_img_path)
    target_img = cv2.imread(target_img_path)

    if source_img is None or target_img is None:
        print("Error loading images. Check paths.")
        return

    # Act face swap
    swapped_img = swapper.smart_face_swap(source_img, target_img)

    # Show the results
    swapper.visualize_results(target_img, swapped_img, title="Swapped Face")

    #Save the output
    cv2.imwrite('swapped_output.jpg', swapped_img)
    print("Saved swapped image as swapped_output.jpg")

if __name__ == "__main__":
    main()