# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from insightface.app import FaceAnalysis
from insightface.model_zoo import get_model
from huggingface_hub import hf_hub_download
import albumentations as A
from sklearn.metrics import mean_squared_error
import torch.nn.functional as F

class FaceDataset(Dataset):
    """Custom dataset for face swapping training"""
    def __init__(self, source_images, target_images, transform=None):
        self.source_images = source_images
        self.target_images = target_images
        self.transform = transform

    def __len__(self):
        return len(self.source_images)

    def __getitem__(self, idx):
        source = self.source_images[idx]
        target = self.target_images[idx]

        if self.transform:
            source = self.transform(source)
            target = self.transform(target)

        return source, target

class FaceSwapNetwork(nn.Module):
    """Custom neural network for face swapping fine-tuning"""
    def __init__(self, input_dim=512, hidden_dim=1024):
        super(FaceSwapNetwork, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim//2),
            nn.ReLU(),
            nn.Dropout(0.3),
        )

        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim//2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Tanh()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

class FineTunedFaceSwapper:
    def __init__(self, ctx_id=0, det_size=(640, 640), device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.app = FaceAnalysis(name='buffalo_l')
        self.app.prepare(ctx_id=ctx_id, det_size=det_size)

        # Load pre-trained model
        model_path = hf_hub_download(
            repo_id="Aitrepreneur/insightface",
            filename="inswapper_128.onnx"
        )
        self.swapper = get_model(model_path, download=False)

        # Custom fine-tuning network
        self.fine_tune_net = FaceSwapNetwork().to(self.device)
        self.optimizer = optim.Adam(self.fine_tune_net.parameters(), lr=0.001)
        self.criterion = nn.MSELoss()

        # Augmentation pipeline
        self.augmentation = A.Compose([
            A.RandomBrightnessContrast(p=0.4),
            A.HueSaturationValue(p=0.4),
            A.GaussNoise(p=0.3),
            A.MotionBlur(p=0.2),
        ])

        # Training history
        self.training_losses = []
        self.validation_losses = []

    def extract_face_features(self, image):
        """Extract face features using InsightFace"""
        faces = self.app.get(image)
        if not faces:
            return None

        # Get the best face
        best_face = max(faces, key=lambda x: x['det_score'])
        return best_face['embedding']

    def prepare_training_data(self, source_images, target_images):
        """Prepare training data by extracting features"""
        source_features = []
        target_features = []

        for src_img, tgt_img in zip(source_images, target_images):
            src_feat = self.extract_face_features(src_img)
            tgt_feat = self.extract_face_features(tgt_img)

            if src_feat is not None and tgt_feat is not None:
                source_features.append(src_feat)
                target_features.append(tgt_feat)

        return np.array(source_features), np.array(target_features)

    def train_epoch(self, dataloader):
        """Train for one epoch"""
        self.fine_tune_net.train()
        epoch_loss = 0.0

        for batch_idx, (source_batch, target_batch) in enumerate(dataloader):
            source_batch = source_batch.to(self.device)
            target_batch = target_batch.to(self.device)

            # Forward pass
            self.optimizer.zero_grad()
            predicted = self.fine_tune_net(source_batch)
            loss = self.criterion(predicted, target_batch)

            # Backward pass
            loss.backward()
            self.optimizer.step()

            epoch_loss += loss.item()

            if batch_idx % 10 == 0:
                print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')

        return epoch_loss / len(dataloader)

    def validate_epoch(self, dataloader):
        """Validate for one epoch"""
        self.fine_tune_net.eval()
        epoch_loss = 0.0

        with torch.no_grad():
            for source_batch, target_batch in dataloader:
                source_batch = source_batch.to(self.device)
                target_batch = target_batch.to(self.device)

                predicted = self.fine_tune_net(source_batch)
                loss = self.criterion(predicted, target_batch)
                epoch_loss += loss.item()

        return epoch_loss / len(dataloader)

    def fine_tune(self, source_images, target_images, epochs=50, batch_size=32, validation_split=0.2):
        """Fine-tune the model with custom data"""
        print("Preparing training data...")
        source_features, target_features = self.prepare_training_data(source_images, target_images)

        # Split data
        split_idx = int(len(source_features) * (1 - validation_split))
        train_src, val_src = source_features[:split_idx], source_features[split_idx:]
        train_tgt, val_tgt = target_features[:split_idx], target_features[split_idx:]

        # Convert to tensors
        train_src = torch.FloatTensor(train_src)
        train_tgt = torch.FloatTensor(train_tgt)
        val_src = torch.FloatTensor(val_src)
        val_tgt = torch.FloatTensor(val_tgt)

        # Create datasets and dataloaders
        train_dataset = FaceDataset(train_src, train_tgt)
        val_dataset = FaceDataset(val_src, val_tgt)

        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

        print(f"Training on {len(train_dataset)} samples, validating on {len(val_dataset)} samples")

        # Training loop
        for epoch in range(epochs):
            print(f"\nEpoch {epoch+1}/{epochs}")

            # Train
            train_loss = self.train_epoch(train_loader)
            self.training_losses.append(train_loss)

            # Validate
            val_loss = self.validate_epoch(val_loader)
            self.validation_losses.append(val_loss)

            print(f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

            # Save checkpoint every 10 epochs
            if (epoch + 1) % 10 == 0:
                self.save_checkpoint(f"checkpoint_epoch_{epoch+1}.pth")

    def save_checkpoint(self, filepath):
        """Save model checkpoint"""
        torch.save({
            'model_state_dict': self.fine_tune_net.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'training_losses': self.training_losses,
            'validation_losses': self.validation_losses
        }, filepath)
        print(f"Checkpoint saved: {filepath}")

    def load_checkpoint(self, filepath):
        """Load model checkpoint"""
        checkpoint = torch.load(filepath, map_location=self.device)
        self.fine_tune_net.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.training_losses = checkpoint['training_losses']
        self.validation_losses = checkpoint['validation_losses']
        print(f"Checkpoint loaded: {filepath}")

    def apply_augmentation(self, image):
        """Apply augmentation to image"""
        aug = self.augmentation(image=image)
        return aug['image']

    def enhanced_face_swap(self, source_img, target_img, use_fine_tuned=True, debug=True):
        """Enhanced face swap with fine-tuning and detailed debugging"""
        if debug:
            print("Starting face swap process...")

        # Get faces from both images
        source_faces = self.app.get(source_img)
        target_faces = self.app.get(target_img)

        if debug:
            print(f"Source faces detected: {len(source_faces) if source_faces else 0}")
            print(f"Target faces detected: {len(target_faces) if target_faces else 0}")

            if source_faces:
                for i, face in enumerate(source_faces):
                    print(f"Source face {i}: confidence={face['det_score']:.3f}")

            if target_faces:
                for i, face in enumerate(target_faces):
                    print(f"Target face {i}: confidence={face['det_score']:.3f}")

        if not source_faces or not target_faces:
            print("Face not detected on source or target")
            return target_img

        # Get best faces with higher confidence threshold
        source_confidences = [f['det_score'] for f in source_faces]
        target_confidences = [f['det_score'] for f in target_faces]

        # Filter faces with low confidence
        min_confidence = 0.5
        good_source_faces = [f for f in source_faces if f['det_score'] > min_confidence]
        good_target_faces = [f for f in target_faces if f['det_score'] > min_confidence]

        if not good_source_faces or not good_target_faces:
            print(f"No faces with confidence > {min_confidence}")
            print("Trying with lower threshold...")
            good_source_faces = source_faces
            good_target_faces = target_faces

        best_source = max(good_source_faces, key=lambda x: x['det_score'])
        best_target = max(good_target_faces, key=lambda x: x['det_score'])

        if debug:
            print(f"Best source face confidence: {best_source['det_score']:.3f}")
            print(f"Best target face confidence: {best_target['det_score']:.3f}")
            print(f"Source face bbox: {best_source['bbox']}")
            print(f"Target face bbox: {best_target['bbox']}")

        # Apply fine-tuning if enabled
        if use_fine_tuned:
            try:
                source_embedding = torch.FloatTensor(best_source['embedding']).unsqueeze(0).to(self.device)

                with torch.no_grad():
                    enhanced_embedding = self.fine_tune_net(source_embedding)
                    best_source['embedding'] = enhanced_embedding.cpu().numpy().flatten()

                if debug:
                    print("Fine-tuning applied to source embedding")
            except Exception as e:
                print(f"Fine-tuning failed: {e}")
                print("Continuing with original embedding...")

        # Perform face swap
        try:
            result = self.swapper.get(target_img, best_target, best_source, paste_back=True)

            if debug:
                print("Face swap completed.")

            return result

        except Exception as e:
            print(f"Face swap failed: {e}")
            print("Trying alternative approach...")

            # Alternative approach: try without paste_back
            try:
                result = self.swapper.get(target_img, best_target, best_source, paste_back=False)
                if debug:
                    print("Face swap completed with paste_back=False")
                return result
            except Exception as e2:
                print(f"Alternative approach also failed: {e2}")
                return target_img

    def plot_training_history(self):
        """Plot training and validation losses"""
        plt.figure(figsize=(12, 4))

        plt.subplot(1, 2, 1)
        plt.plot(self.training_losses, label='Training Loss')
        plt.plot(self.validation_losses, label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training History')
        plt.legend()

        plt.subplot(1, 2, 2)
        plt.plot(self.training_losses[-20:], label='Training Loss (Last 20)')
        plt.plot(self.validation_losses[-20:], label='Validation Loss (Last 20)')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Recent Training History')
        plt.legend()

        plt.tight_layout()
        plt.show()

    def visualize_face_detection(self, image, title="Face Detection"):
        """Visualize detected faces with bounding boxes"""
        faces = self.app.get(image)
        img_copy = image.copy()

        if faces:
            for i, face in enumerate(faces):
                bbox = face['bbox'].astype(int)
                confidence = face['det_score']

                # Draw bounding box
                cv2.rectangle(img_copy, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)

                # Draw confidence score
                cv2.putText(img_copy, f'{confidence:.3f}',
                           (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                # Draw face landmarks if available
                if 'kps' in face:
                    kps = face['kps'].astype(int)
                    for kp in kps:
                        cv2.circle(img_copy, tuple(kp), 2, (255, 0, 0), -1)

        plt.figure(figsize=(10, 8))
        plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))
        plt.title(f"{title} - {len(faces)} faces detected")
        plt.axis('off')
        plt.show()

        return faces

    def simple_face_swap(self, source_img, target_img, debug=True):
        """Basit face swap fonksiyonu - sorun giderme için"""
        if debug:
            print("=== Simple Face Swap Debug ===")

        # Face recognition
        source_faces = self.app.get(source_img)
        target_faces = self.app.get(target_img)

        if debug:
            print(f"Source faces: {len(source_faces) if source_faces else 0}")
            print(f"Target faces: {len(target_faces) if target_faces else 0}")

        if not source_faces:
            print("No face has been found in source image!")
            return target_img

        if not target_faces:
            print("No face has been found in target image!")
            return target_img

        # Best faces
        best_source = source_faces[0]  # First face
        best_target = target_faces[0]  # First face

        if debug:
            print(f"Source confidence: {best_source['det_score']:.3f}")
            print(f"Target confidence: {best_target['det_score']:.3f}")

        # Face swap
        try:
            result = self.swapper.get(target_img, best_target, best_source, paste_back=True)
            if debug:
                print("Face swap is successful!")
            return result
        except Exception as e:
            if debug:
                print(f"Face swap error: {e}")
            return target_img
        """Show comparison of results"""
        if enhanced_swapped_img is not None:
            plt.figure(figsize=(20, 5))
            plt.subplot(1, 4, 1)
            plt.imshow(cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB))
            plt.title("Target Image")
            plt.axis("off")

            plt.subplot(1, 4, 2)
            plt.imshow(cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB))
            plt.title("Source Image")
            plt.axis("off")

            plt.subplot(1, 4, 3)
            plt.imshow(cv2.cvtColor(swapped_img, cv2.COLOR_BGR2RGB))
            plt.title("Original Swap")
            plt.axis("off")

            plt.subplot(1, 4, 4)
            plt.imshow(cv2.cvtColor(enhanced_swapped_img, cv2.COLOR_BGR2RGB))
            plt.title("Fine-tuned Swap")
            plt.axis("off")
        else:
            plt.figure(figsize=(15, 5))
            plt.subplot(1, 3, 1)
            plt.imshow(cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB))
            plt.title("Target Image")
            plt.axis("off")

            plt.subplot(1, 3, 2)
            plt.imshow(cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB))
            plt.title("Source Image")
            plt.axis("off")

            plt.subplot(1, 3, 3)
            plt.imshow(cv2.cvtColor(swapped_img, cv2.COLOR_BGR2RGB))
            plt.title("Swapped Result")
            plt.axis("off")

        plt.tight_layout()
        plt.show()

def main():
    # Initialize the fine-tuned face swapper
    swapper = FineTunedFaceSwapper()

    # Example usage for inference
    source_path = ""  # Add your source image path
    target_path = ""  # Add your target image path

    source_img = cv2.imread(source_path)
    target_img = cv2.imread(target_path)

    if source_img is None or target_img is None:
        print("Error to upload!")
        return

    print("Continuing...")

    print("\n--- Source face recognition ---")
    source_faces = swapper.visualize_face_detection(source_img, "Source Image")

    print("\n--- Target face recognition ---")
    target_faces = swapper.visualize_face_detection(target_img, "Target Image")

    if not source_faces or not target_faces:
        print("Error!")
        return

    # Simple face swap
    print("\n🔄 Simple face swap is being tried...")
    simple_swapped = swapper.simple_face_swap(source_img, target_img, debug=True)

    # Augmentation
    print("\n🎨 Augmentation ...")
    augmented_source = swapper.apply_augmentation(source_img)

    # Improved face swap
    print("\n🔄 Improved face swap is being tried...")
    enhanced_swapped = swapper.enhanced_face_swap(augmented_source, target_img, use_fine_tuned=False, debug=True)

    # Results
    print("\nResults are being uploaded...")

    plt.figure(figsize=(20, 10))

    # Orijinal images
    plt.subplot(2, 4, 1)
    plt.imshow(cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB))
    plt.title("Source")
    plt.axis("off")

    plt.subplot(2, 4, 2)
    plt.imshow(cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB))
    plt.title("Target")
    plt.axis("off")

    plt.subplot(2, 4, 3)
    plt.imshow(cv2.cvtColor(augmented_source, cv2.COLOR_BGR2RGB))
    plt.title("Augmented")
    plt.axis("off")

    plt.subplot(2, 4, 4)
    plt.imshow(cv2.cvtColor(simple_swapped, cv2.COLOR_BGR2RGB))
    plt.title("Simple Face Swap")
    plt.axis("off")

    # Low line
    plt.subplot(2, 4, 5)
    plt.imshow(cv2.cvtColor(enhanced_swapped, cv2.COLOR_BGR2RGB))
    plt.title("Improved Face Swap")
    plt.axis("off")


    plt.subplot(2, 4, 8)

    # Histogram comparison
    plt.hist(target_img.ravel(), bins=256, alpha=0.5, label='Hedef', color='red')
    plt.hist(simple_swapped.ravel(), bins=256, alpha=0.5, label='Swap', color='blue')
    plt.legend()
    plt.title("Histogram comparison")

    plt.tight_layout()
    plt.show()

    # Save the results
    cv2.imwrite("simple_swapped.jpg", simple_swapped)
    cv2.imwrite("enhanced_swapped.jpg", enhanced_swapped)
    cv2.imwrite("augmented_source.jpg", augmented_source)


if __name__ == "__main__":
    main()